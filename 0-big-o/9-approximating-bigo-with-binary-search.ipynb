{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big O and Binary Search\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "So far with time complexity, we consider the worst case because that is when we tend to feel the costs of performance.  Well, with time complexity, we also are really only concerned with large datasets.   This is because, when the amount of data is small, the time it takes the computer to perform the operation is a non-issue.  By this, we mean a size in the tens of thousands, but of course our amount of data could be much larger.  \n",
    "\n",
    "Because of this, time complexity is sometimes called **asymptotic time complexity**.  \n",
    "\n",
    ">  By **asymptotic**, we mean to consider what occurs as *n* -- the length of our input -- approaches infinity.\n",
    "\n",
    "This is how we really calculate the cost of our function, by asking what is the worst case scenario when our input gets really large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our second algorithm: a worthy alternative\n",
    "\n",
    "In the last section, we answered whether a list included a target number by moving through each element in the list, one by one.  Our function looked like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = [3, 1, 9, 0, 2, 6, 4]\n",
    "target = 6\n",
    "\n",
    "def is_in(elements, target):\n",
    "    for element in elements:\n",
    "        if element == target:\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_in(elements, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what changes if our list is sorted.  We'll discuss the cost of sorting later, but for now let's assume that we can sort for free, perhaps with our `sorted` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsorted = [15, 76, 86, 97, 98, 18, 34, 42, 23, 43, 77, 78, 70, 61, 87, 37, 60,\n",
    "       19, 50, 53, 95, 39,  0, 47,  2, 71, 27, 73, 90, 69, 85, 68,  5, 35,\n",
    "       72, 22, 25,  3]\n",
    "\n",
    "sorted_nums = [ 0,  2,  3,  5, 15, 18, 19, 22, 23, 25, 27, 34, 35, 37, 39, 42, 43,\n",
    "       47, 50, 53, 60, 61, 68, 69, 70, 71, 72, 73, 76, 77, 78, 85, 86, 87,\n",
    "       90, 95, 97, 98]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we ask you -- without programming -- which is easier, seeing if the number 18 exists in the sorted list or in the unsorted list, which would you choose?\n",
    "\n",
    "Or, going further, what set of procedures could we write to check this sorted list.\n",
    "\n",
    "> In describing these steps the task is to translate what your brain somehow performed naturally into individual steps, and then turn those steps into code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction of Binary Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here is our procedure.  We'll make a guess in the middle of the list and see if this guess is our number (18).  If the guessed number (say 12) is below our target (of 18), then we can just select the upper half, as our list is sorted.  Then we can repeat the procedure. \n",
    "\n",
    "In other words, we can again divide our remaining list down the middle and guess the middle element, and if that middle element is below our target we remove that lower half of the list.  So each time, we are cutting our list in half.\n",
    "\n",
    "Let's take a look at this procedure in a diagram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./binary_search_diag.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Binary search divides the dataset with each attempt to find a match.\n",
    "\n",
    "Let's look at our old technique and our new technique side by side.  Also, let's name our new function binarySearch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(elements, target):\n",
    "    starting_idx = 0\n",
    "    ending_idx = len(elements) - 1\n",
    "    guess_idx = int(round(ending_idx/2, 0))\n",
    "    while (starting_idx != ending_idx):\n",
    "        print(f\"starting at {starting_idx} \", \n",
    "              f\"ending at {ending_idx} \", \n",
    "              f\"and guess index is {guess_idx}\")\n",
    "        if elements[guess_idx] < target:\n",
    "            print(\"too low\")\n",
    "            starting_idx = guess_idx\n",
    "            guess_idx = starting_idx + int(round((ending_idx - starting_idx)/2, 0))\n",
    "        elif(elements[guess_idx] > target):\n",
    "            print('too high')\n",
    "            ending_idx = guess_idx\n",
    "            guess_idx = starting_idx + int(round((ending_idx - starting_idx)/2, 0))\n",
    "        else:\n",
    "            print(f\"found {target} at idx {guess_idx}\")\n",
    "            return True\n",
    "    print(f'No target {target}')\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_nums = [ 0,  2,  3,  5, 15, 18, 19, 22, 23, 25, 27, 34, 35, 37, 39, 42, 43,\n",
    "       47, 50, 53, 60, 61, 68, 69, 70, 71, 72, 73, 76, 77, 78, 85, 86, 87,\n",
    "       90, 95, 97, 98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting at 0  ending at 37  and guess index is 18\n",
      "too high\n",
      "starting at 0  ending at 18  and guess index is 9\n",
      "too high\n",
      "starting at 0  ending at 9  and guess index is 4\n",
      "too high\n",
      "starting at 0  ending at 4  and guess index is 2\n",
      "too high\n",
      "starting at 0  ending at 2  and guess index is 1\n",
      "too high\n",
      "starting at 0  ending at 1  and guess index is 0\n",
      "too high\n",
      "No target -999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(sorted_nums, -999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Time Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the time complexity for both functions.  As we'll see, our two functions are quite different in terms how performant they are.  Let's move through it.\n",
    "\n",
    "  1. *Consider the worse case scenario in both functions*\n",
    "  \n",
    "The worst case scenario is the same for each function.  The worst case would be where we have to keep guessing until we can conclude that the number is not in our list. \n",
    "     \n",
    " 2. *Calculate the cost as the size of our input varies*\n",
    "\n",
    "Ok, so we already concluded the cost of our `is_in` function was $n + 1$ where n is the length of the list.  What is the cost of the `binary_search` function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important item to calculate is the number of times we travel through the `while` loop above.  Because the function cuts what we search through in half every time we pass through the loop, we can make the following chart:\n",
    "\n",
    "| Input size (n) | Number of guesses |\n",
    "| ------------- |-------------|\n",
    "| 1 | 0 |\n",
    "| 2 | 1 |\n",
    "| 4 | 2 |\n",
    "| 8 | 3 |\n",
    "| 16 | 4 |\n",
    "| 1024 | 10 |\n",
    "| 2048 | 11 |\n",
    "| 4096 | 12 |\n",
    "| 1,048,576 | 20 |   \n",
    "| n | log2(n) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so as you see above, as our input size increases, the number of guesses involved in our `binary_search` funtion increases slowly.   We can answer the question of whether a number is in a list of over one million elements, in only twenty guesses. \n",
    "\n",
    "And just as we could express the time complexity of our original method in terms of the size of the input string (n), we can do so with binary search as well.  The time complexity of our binary search function is logâ‚‚n (log base 2 of n, also written lg(n)).  Log base 2 of n means the number of times you would have to press \"divided by two\" on a calculator to get down to 1, starting with the number n - it's the inverse of the exponent function. \n",
    "\n",
    "In our binary search algorithm, when the size of n gets over 1 million, it still only takes us about 20 guesses.  Our other formula would have taken one million guesses for an input of that size. Taking a close look at the chart above, we can see that when our input size **doubles**, our guesses only increases by 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying Time Complexity\n",
    "\n",
    "So at this point, it's pretty meaningless to add 3 to our cost for those first three lines in our binary search function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also meaningless to count up lines inside our loop and say that each time we loop through the code it costs us four and not one.  The cost of binary search would still only be eighty for an input size of over one million.  \n",
    "\n",
    "So when we consider time complexity, we never care about how much we need to add or multiply by.  Rather the only number we care about is the leading exponent of our formula.  You may remember this from our Google Search a few lessons ago.\n",
    "\n",
    "![](https://s3-us-west-2.amazonaws.com/curriculum-content/web-development/algorithms/time-complexity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can now begin to understand that second sentence, \"excludes coefficients and lower order terms.\"  Coefficients just mean anything that we multiply $n$ by, and exclude lower order terms means that we should only consider the \"term\" with the highest exponent.  \n",
    "\n",
    "> For example, let's say that the time complexity of our function is $5n^3 + n^2 + 100n + > log_2(n) + 100$.  \n",
    "\n",
    "> Then $n^3$, $n^2$, $100n$, $log_2(n)$ and $100$ are all \"terms\" of the function.  Excluding the lower order terms we would say that the time complexity of our function is $5n^3$, and excluding $n^3$'s coefficient of $5$ we would say that the time complexity is  $n^3$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the Internet told us to exclude co-efficients and lower order terms, but can we really just get get away with that?\n",
    "\n",
    "Well let's assume the time complexity of our function and is **$n^3 + n^2 + n + log2(n) + 100$** and assume that $n = 1,000$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000000, 1000000, 1000, 6.907755278982137, 100)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 1000\n",
    "costs_of_terms = (n**3, n**2, n, np.log(n), 100)\n",
    "costs_of_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001001106.9077553"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost = sum(costs_of_terms)\n",
    "total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that with the above terms when n is 1000, the formula returns approximately 1,001,001,110. \n",
    "\n",
    "Moreover, you can see that compared to $n^3$, the $n^2$ doesn't move the dial.  It accounts for just 1,000th of our overall cost.  And this is still when our n is relatively small.  Imagine if our input size were to increase to ten thousand.  So this is why we only consider the leading exponent when calculating the cost of our function. \n",
    "\n",
    "Now if we can exclude something like nÂ², can we also exclude our leading coefficients?  The answer is yes.  Any number we multiply by won't really have an impact.    \n",
    "\n",
    "So in summary, when considering asymptoptic time complexity, we only look to the term with the largest exponent, we only consider the worse case scenario, and we ignore coefficients as well as any smaller terms.  \n",
    "\n",
    "We call this big O."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Big O\n",
    "\n",
    "Ok, so now we have learned that when expressing the cost of an algorithm, we only consider the term with the largest exponent.  So, the next question is, is there a good technique to calculate the big O of a function?  Yes there is  \n",
    "\n",
    "Let's look at a couple of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_loop(elements):\n",
    "    for i in elements:\n",
    "        print(i)\n",
    "        for i in elements:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested_loop([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The big O of the above function is $n^2$.  The reason why is because the inner loop has a cost of three (if we pass through 1, 2, and 3).  And then how many times does the outer loop call the inner loop?  Well three times.  So we incur a cost of three, three times leading to a total cost is nine.  So moving to a list of length $n$, we go through the inner loop $n$ times, and the cost of that inner loop is $n$, giving us a total cost of $n^2$.\n",
    "\n",
    "Now let's look at $n^3$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def further_nested_loop(elements):\n",
    "    for i in elements:\n",
    "        for i in elements:\n",
    "            print(i)\n",
    "            for i in elements:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One way of thinking about the above function is our outer most loop goes through our two inner loops n times.  And we know that the cost of those two inner loops is $n^2$, so now our total cost is $n * n^2 = n^3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the point: to calculate the big O of a function if each loop forces you to go through your dataset n times, *just count the number of nested loops*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is one gotcha.  The big O of the below function is not $n^2$.  It's just $n$. Do you see why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_loops(elements):\n",
    "    for i in elements:\n",
    "            print(i)\n",
    "    for i in elements:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function above, our loop isn't nessted.  So we loop through our elements two times, giving us a big of 2n.  And because we ignore multipliers we have a big O of n.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another gotcha: be careful of code that is calling methods that rely on loops.  So we saw that one such method was our `in` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remember_in(elements, target):\n",
    "    for i in elements:\n",
    "        print(target in elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the function above would really have a cost of $n^2$, as the cost of each `in` call is $n$.  Another method is anytime we sort a collection -- there we can assume the cost is `O(n * log2(n))`.\n",
    "\n",
    "> We'll discuss the cost of various Python functions in future lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section we saw that when the input size is large (meaning over ten thousand or so), the leading exponent dominates our calculation of the cost of an algorithm, and so we can ignore considerations like smaller exponents, multipliers of an exponent and any number we need to add by.  Then we saw that we can calculate the big O of a function by generally counting the number of nested loops that ask us to traverse through each number."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
